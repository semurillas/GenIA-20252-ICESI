# UNIVERSIDAD ICESI
<h1>ğŸ“š MaestrÃ­a en Inteligencia Artificial Aplicada â€“ 3er Semestre</h1>

<h3>Asignatura: Inteligencia Artificial Generativa</h3>

<h4>Taller PrÃ¡ctico Nro. 1 </h4>


<hr style="width:60%;">

<h2>ğŸ‘¨â€ğŸ“ Estudiantes</h2>
<ul style="list-style:none; padding:0; font-size:18px;">
    <li>SebastiÃ¡n Murillas</li>
    <li>Octavio Guerra</li>
</ul>

<hr style="width:60%;">

<h3>ğŸ“… Fecha: Septiembre 26, 2025</h3>

---
# Propuesta de Arquitectura HÃ­brida de Modelos LLM para EcoMarket

DespuÃ©s de varias sesiones donde hemos revisado literatura y documentaciÃ³n de Modelos de LLM y teorÃ­a sobre Inteligencia Artificial Generativa, nos hemos decidido por una soluciÃ³n **â€œHÃ­bridaâ€** para resolver los altos tiempos de respuesta, 24 horas en promedio, que estÃ¡ impactando a la compaÃ±Ã­a **EcoMarket** en la mÃ©trica de **SatisfacciÃ³n del Cliente**.

---

## 1. Arquitectura General

Nuestro Modelo HÃ­brido estÃ¡ compuesto por:

1. **Modelo Fine Tuned LLM**, para atender el **80%** de las consultas repetitivas.  
2. **Modelo LLM** de propÃ³sito general, para atender las consultas o preguntas complejas.

### Â¿Por quÃ©?

Esta arquitectura permite que el modelo Fine-Tuned se enfoque en **eficiencia**, mientras que el LLM aporta **capacidad de comprensiÃ³n** en consultas complejas.  
Esto resolverÃ¡ el problema mÃ¡s importante de EcoMarket: **reducir los tiempos de respuesta de 24 horas a minutos**.  

En cuanto a costos, usar un esquema HÃ­brido permite:  
- Operar con un **presupuesto moderado** para resolver la parte repetitiva.  
- **Estimar un costo lÃ­mite mÃ¡ximo** al usar un LLM en los casos complejos.  

La elecciÃ³n del modelo se basa en un anÃ¡lisis de **costo-beneficio** centrado en la tarea especÃ­fica que debe resolver cada componente.

---

### 1.1. Para el 80% de Consultas (Repetitivas: Pedidos, Devoluciones, CatÃ¡logo)

**Modelo Elegido (Ejemplo):** LLM Ligero y Open Source (e.g., *Mistral 7B*) + Afinamiento (Fine-Tuning)

| Criterio               | JustificaciÃ³n |
|-------------------------|---------------|
| **Necesidad de PrecisiÃ³n** | Alta. Una respuesta incorrecta sobre el estado de un pedido (ej: "entregado" cuando estÃ¡ "en camino") es crÃ­tica para la satisfacciÃ³n. |
| **Ventaja del Afinamiento** | Al aplicar Fine-Tuning sobre un modelo ligero base (como Mistral 7B), el modelo aprende el vocabulario, la estructura de las preguntas frecuentes y el tono de EcoMarket. Esto permite rapidez y precisiÃ³n en su dominio. |
| **Costo Operacional** | Bajo. Los modelos ligeros son mÃ¡s baratos de alojar en infraestructura propia o en la nube. Solo se activan cuando se requieren, manejando eficientemente el grueso del trÃ¡fico. |

---

### 1.2. Para el 20% de Consultas (Complejas: Quejas, Problemas, Sugerencias)

**Modelo Elegido (Ejemplo):** LLM de PropÃ³sito General de Alto Rendimiento (e.g., *GPT-4o, Gemini 1.5 Pro*)

| Criterio               | JustificaciÃ³n |
|-------------------------|---------------|
| **Necesidad de Fluidez/Razonamiento** | Alta. Estas consultas exigen comprender el contexto emocional (empatÃ­a), sintetizar informaciÃ³n de mÃºltiples fuentes y seguir instrucciones complejas. |
| **Ventaja de Rendimiento** | Modelos como GPT-4o y Gemini 1.5 Pro poseen razonamiento en cadena (*chain-of-thought*) y uso de herramientas (*Function Calling*). Esto permite clasificar y derivar quejas a los agentes correctos, con un resumen pre-analizado. |
| **Costo Operacional** | Moderado/Alto. El costo por token es mayor, pero al representar solo el 20% del volumen de trÃ¡fico, la inversiÃ³n se justifica porque impacta directamente en la **SatisfacciÃ³n del Cliente (CSAT)**. |

---

## 2. Arquitectura Propuesta

Nuestra arquitectura es un **sistema de OrquestaciÃ³n** con **decisiÃ³n basada en el trÃ¡fico**, combinando modelos Fine-Tuned con modelos de PropÃ³sito General.

### 2.1. Arquitectura LÃ³gica

1. **Orquestador/Router:**  
   - Recibe cada consulta del cliente.  
   - Usa un modelo ligero (ej: *GPT-4o Mini*) afinado para clasificaciÃ³n.  
   - Decide: Â¿Es repetitiva (80%) o compleja (20%)?  

2. **Ruta del 80% (Eficiencia):**  
   - La consulta pasa al **Modelo Fine-Tuned**.  
   - Este modelo integra una capa de **RAG (Retrieve Augmented Generation)** para consultar la base de datos de EcoMarket.  

3. **Ruta del 20% (Capacidad):**  
   - La consulta pasa al **Modelo Potente**.  
   - Este modelo usa **Function Calling** para iniciar procesos especializados (ej: registrar una queja en el CRM o generar un ticket de soporte).  

---

### 2.2. IntegraciÃ³n con la Base de Datos (BD) de EcoMarket

| Mecanismo de IntegraciÃ³n | PropÃ³sito | AplicaciÃ³n en EcoMarket |
|--------------------------|-----------|--------------------------|
| **RAG (Retrieve Augmented Generation)** | Consultar datos en tiempo real (solo lectura). | Estado del pedido, informaciÃ³n de envÃ­o, inventario y catÃ¡logo. |
| **Function Calling / Herramientas** | Ejecutar acciones o registrar datos (lectura y escritura). | Registrar devoluciones, actualizar quejas o ejecutar scripts de diagnÃ³stico. |

---

### 2.3. PropÃ³sito del Modelo

El sistema propuesto combina:  
- **Modelo de propÃ³sito general** (el Router y el 20%),  
- **Datos especÃ­ficos de la empresa** (80% mediante Fine-Tuning y RAG).  

---

## 3. JustificaciÃ³n Basada en Criterios de IngenierÃ­a

| Criterio               | JustificaciÃ³n |
|-------------------------|---------------|
| **Costo** | OptimizaciÃ³n del TCO. El 80% del trÃ¡fico va a un LLM Fine-Tuned econÃ³mico (ej. Mistral 7B). Solo se paga un modelo premium para el 20% de casos crÃ­ticos. |
| **Escalabilidad** | Escalabilidad paralela: el 80% se maneja con clusters de modelos ligeros en GPUs econÃ³micas. El 20% escala en la nube de proveedores de LLM de alto nivel (OpenAI/Google). |
| **Facilidad de IntegraciÃ³n** | Uso de estÃ¡ndares como RAG y Function Calling, lo que simplifica el desarrollo y reduce la curva de aprendizaje del equipo de ingenierÃ­a. |
| **Calidad de Respuesta** | PrecisiÃ³n garantizada en el 80% repetitivo (Fine-Tuning + RAG) y razonamiento superior en el 20% complejo (modelos avanzados). |

---

```mermaid
graph TD
    subgraph "Entrada de Consulta"
        A[Cliente: Chat, Email, RRSS] --> B(MÃ³dulo de ClasificaciÃ³n);
    end

    subgraph "Flujo Automatizado (Respuestas Repetitivas)"
        subgraph "ClasificaciÃ³n (BART)"
            B -- "80% Consultas Repetitivas" --> C[Pedido, DevoluciÃ³n, Producto];
        end
        subgraph "Respuestas AutomÃ¡ticas (T5)"
            C --> D[T5 se conecta a la Base de Datos de EcoMarket];
            D --> E[Genera Respuesta Personalizada];
            E --> F[Respuesta RÃ¡pida Enviada al Cliente];
        end
    end

    subgraph "Flujo Humano Asistido (Consultas Complejas)"
        subgraph "ClasificaciÃ³n (BART)"
            B -- "20% Consultas Complejas" --> G[Queja, Problema TÃ©cnico];
        end
        subgraph "Asistente de IA (GPT-3.5)"
            G --> H[GPT-3.5 asiste al Agente de Soporte];
            H --> I[Genera Borradores de Respuesta y ResÃºmenes];
            I --> J[Agente Humano Edita y Personaliza];
            J --> K[Respuesta con EmpatÃ­a Enviada al Cliente];
        end
    end

    style A fill:#D4E6F1,stroke:#333,stroke-width:2px;
    style B fill:#AED6F1,stroke:#333,stroke-width:2px;
    style C fill:#C0F6C0,stroke:#333,stroke-width:2px;
    style D fill:#C0F6C0,stroke:#333,stroke-width:2px;
    style E fill:#C0F6C0,stroke:#333,stroke-width:2px;
    style F fill:#D4E6F1,stroke:#333,stroke-width:2px;
    style G fill:#F6C0C0,stroke:#333,stroke-width:2px;
    style H fill:#F6C0C0,stroke:#333,stroke-width:2px;
    style I fill:#F6C0C0,stroke:#333,stroke-width:2px;
    style J fill:#F6C0C0,stroke:#333,stroke-width:2px;
    style K fill:#F6C0C0,stroke:#333,stroke-width:2px;
```
