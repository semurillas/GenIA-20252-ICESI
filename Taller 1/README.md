<h1> <img width="207" height="112" alt="image" src="https://github.com/user-attachments/assets/89fd906b-04fb-4d4f-b5e6-8375083a8a01" /></h1>
<h1>üìö Maestr√≠a en Inteligencia Artificial Aplicada ‚Äì 3er Semestre</h1>

<h3>Asignatura: Inteligencia Artificial Generativa</h3>

<h3>Taller Pr√°ctico Nro. 1 </h3>

<hr style="width:60%;">

<h3>üë®‚Äçüéì Estudiantes</h3>
<ul style="list-style:none; padding:0; font-size:18px;">
    <li>Sebasti√°n Murillas</li>
    <li>Octavio Guerra</li>
</ul>

<hr style="width:60%;">

<h3>üìÖ Fecha: Septiembre 26, 2025</h3>

---
# Fase I - Propuesta de Arquitectura IAG para Optimizaci√≥n del servicio al Cliente de la compa√±ia EcoMarket

Despu√©s de varias sesiones donde hemos revisado literatura y documentaci√≥n de Modelos de LLM y teor√≠a sobre Inteligencia Artificial Generativa, nos hemos decidido por una soluci√≥n **‚ÄúH√≠brida‚Äù** para resolver los altos tiempos de respuesta, 24 horas en promedio, que est√° impactando a la compa√±√≠a **EcoMarket** en la m√©trica de **Satisfacci√≥n del Cliente**.

---

## 1. Arquitectura General

Nuestro Modelo H√≠brido est√° compuesto por:

1. **Modelo Fine Tuned LLM**, para atender el **80%** de las consultas repetitivas.  
2. **Modelo LLM** de prop√≥sito general, para atender las consultas o preguntas complejas (**20%**).

### ¬øPor qu√©?

Esta arquitectura permite que el modelo Fine-Tuned se enfoque en **eficiencia**, mientras que el LLM aporta **capacidad de comprensi√≥n** en consultas complejas.  
Esto resolver√° el problema m√°s importante de EcoMarket: **reducir los tiempos de respuesta de 24 horas a minutos**.  

En cuanto a costos, usar un esquema H√≠brido permite:  
- Operar con un **presupuesto moderado** para resolver la parte repetitiva.  
- **Estimar un costo l√≠mite m√°ximo** al usar un LLM en los casos complejos.  

La elecci√≥n del modelo se basa en un an√°lisis de **costo-beneficio** centrado en la tarea espec√≠fica que debe resolver cada componente.

---

### 1.1. Para el 80% de Consultas (Repetitivas: Pedidos, Devoluciones, Cat√°logo)

**Modelo Elegido (Ejemplo):** LLM Ligero y Open Source (e.g., *Mistral 7B*) + Afinamiento (Fine-Tuning)

| Criterio               | Justificaci√≥n |
|-------------------------|---------------|
| **Necesidad de Precisi√≥n** | Alta. Una respuesta incorrecta sobre el estado de un pedido (ej: "entregado" cuando est√° "en camino") es cr√≠tica para la satisfacci√≥n. |
| **Ventaja del Afinamiento** | Al aplicar Fine-Tuning sobre un modelo ligero base (como Mistral 7B), el modelo aprende el vocabulario, la estructura de las preguntas frecuentes y el tono de EcoMarket. Esto permite rapidez y precisi√≥n en su dominio. |
| **Costo Operacional** | Bajo. Los modelos ligeros son m√°s baratos de alojar en infraestructura propia o en la nube. Solo se activan cuando se requieren, manejando eficientemente el grueso del tr√°fico. |

---

### 1.2. Para el 20% de Consultas (Complejas: Quejas, Problemas, Sugerencias)

**Modelo Elegido (Ejemplo):** LLM de Prop√≥sito General de Alto Rendimiento (e.g., *GPT-4o, Gemini 1.5 Pro*)

| Criterio               | Justificaci√≥n |
|-------------------------|---------------|
| **Necesidad de Fluidez/Razonamiento** | Alta. Estas consultas exigen comprender el contexto emocional (empat√≠a), sintetizar informaci√≥n de m√∫ltiples fuentes y seguir instrucciones complejas. |
| **Ventaja de Rendimiento** | Modelos como GPT-4o y Gemini 1.5 Pro poseen razonamiento en cadena (*chain-of-thought*) y uso de herramientas (*Function Calling*). Esto permite clasificar y derivar quejas a los agentes correctos, con un resumen pre-analizado. |
| **Costo Operacional** | Moderado/Alto. El costo por token es mayor, pero al representar solo el 20% del volumen de tr√°fico, la inversi√≥n se justifica porque impacta directamente en la **Satisfacci√≥n del Cliente (CSAT)**. |

---

## 2. Arquitectura Propuesta

Nuestra arquitectura es un **sistema de Orquestaci√≥n** con **decisi√≥n basada en el tr√°fico**, combinando modelos Fine-Tuned con modelos de Prop√≥sito General.

```mermaid
graph TD
    subgraph "Entrada de Consulta"
        A["Cliente: Chat, Email, RRSS"] --> B["Orquestador / Router"];
    end

    subgraph "Clasificaci√≥n - Router Ligero"
        B -- "80% Consultas Repetitivas" --> C["Pedidos, Devoluciones, Cat√°logo"];
        B -- "20% Consultas Complejas" --> G["Quejas, Problemas, Sugerencias"];
    end

    subgraph "Ruta 80% - Consultas Repetitivas"
        C --> D["LLM Fine-Tuned - Ej: Mistral 7B, LLaMA 2-7B"];
        D --> E["RAG conectado a BD de EcoMarket"];
        E --> F["Genera Respuesta Personalizada"];
        F --> Z["Respuesta Autom√°tica Enviada al Cliente"];
    end

    subgraph "Ruta 20% - Consultas Complejas"
        G --> H["LLM Potente - Ej: GPT-4o, Gemini 1.5 Pro, Claude 3 Opus"];
        H --> I["Function Calling / Integraci√≥n CRM & Tickets"];
        I --> J["Genera Resumen o Acci√≥n"];
        J --> K["Agente Humano Ajusta y Env√≠a"];
    end

    %% Estilos
    style A fill:#D4E6F1,stroke:#333,stroke-width:2px;
    style B fill:#AED6F1,stroke:#333,stroke-width:2px;

    style C fill:#C0F6C0,stroke:#333,stroke-width:2px;
    style D fill:#C0F6C0,stroke:#333,stroke-width:2px;
    style E fill:#C0F6C0,stroke:#333,stroke-width:2px;
    style F fill:#C0F6C0,stroke:#333,stroke-width:2px;
    style Z fill:#D4E6F1,stroke:#333,stroke-width:2px;

    style G fill:#F6C0C0,stroke:#333,stroke-width:2px;
    style H fill:#F6C0C0,stroke:#333,stroke-width:2px;
    style I fill:#F6C0C0,stroke:#333,stroke-width:2px;
    style J fill:#F6C0C0,stroke:#333,stroke-width:2px;
    style K fill:#F6C0C0,stroke:#333,stroke-width:2px;
```
### 2.1. Arquitectura L√≥gica

1. **Orquestador/Router:**  
   - Recibe cada consulta del cliente.  
   - Usa un modelo ligero (ej: *GPT-4o Mini*) afinado para clasificaci√≥n.  
   - Decide: ¬øEs repetitiva (80%) o compleja (20%)?  

2. **Ruta del 80% (Eficiencia):**  
   - La consulta pasa al **Modelo Fine-Tuned**.  
   - Este modelo integra una capa de **RAG (Retrieve Augmented Generation)** para consultar la base de datos de EcoMarket.  

3. **Ruta del 20% (Capacidad):**  
   - La consulta pasa al **Modelo Potente**.  
   - Este modelo usa **Function Calling** para iniciar procesos especializados (ej: registrar una queja en el CRM o generar un ticket de soporte).  

---

### 2.2. Integraci√≥n con la Base de Datos (BD) de EcoMarket

| Mecanismo de Integraci√≥n | Prop√≥sito | Aplicaci√≥n en EcoMarket |
|--------------------------|-----------|--------------------------|
| **RAG (Retrieve Augmented Generation)** | Consultar datos en tiempo real (solo lectura). | Estado del pedido, informaci√≥n de env√≠o, inventario y cat√°logo. |
| **Function Calling / Herramientas** | Ejecutar acciones o registrar datos (lectura y escritura). | Registrar devoluciones, actualizar quejas o ejecutar scripts de diagn√≥stico. |

---

## 3. Justificaci√≥n

| Criterio               | Justificaci√≥n |
|-------------------------|---------------|
| **Costo** | Optimizaci√≥n del TCO. El 80% del tr√°fico va a un LLM Fine-Tuned econ√≥mico (ej. Mistral 7B). Solo se paga un modelo premium para el 20% de casos cr√≠ticos. |
| **Escalabilidad** | Escalabilidad paralela: el 80% se maneja con clusters de modelos ligeros en GPUs econ√≥micas. El 20% escala en la nube de proveedores de LLM de alto nivel (OpenAI/Google). |
| **Facilidad de Integraci√≥n** | Uso de est√°ndares como RAG y Function Calling, lo que simplifica el desarrollo y reduce la curva de aprendizaje del equipo de ingenier√≠a. |
| **Calidad de Respuesta** | Precisi√≥n garantizada en el 80% repetitivo (Fine-Tuning + RAG) y razonamiento superior en el 20% complejo (modelos avanzados). |

---

# Fase II - Evaluaci√≥n de Fortalezas, Limitaciones y Riesgos √âticos

