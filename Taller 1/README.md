<h1> <img width="207" height="112" alt="image" src="https://github.com/user-attachments/assets/89fd906b-04fb-4d4f-b5e6-8375083a8a01" /></h1>
<h1>üìö Maestr√≠a en Inteligencia Artificial Aplicada ‚Äì 3er Semestre</h1>

<h3>Asignatura: Inteligencia Artificial Generativa</h3>

<h3>Taller Pr√°ctico Nro. 1 </h3>

<hr style="width:60%;">

<h3>üë®‚Äçüéì Estudiantes</h3>
<ul style="list-style:none; padding:0; font-size:18px;">
    <li>Sebasti√°n Murillas</li>
    <li>Octavio Guerra</li>
</ul>

<hr style="width:60%;">

<h3>üìÖ Fecha: Septiembre 28, 2025</h3>

---
# Fase I - Propuesta de Arquitectura IAG para Optimizaci√≥n del servicio al Cliente de la compa√±ia EcoMarket


Tras revisar la literatura y la documentaci√≥n sobre Modelos de Lenguaje Grande (LLM) y la teor√≠a de la Inteligencia Artificial Generativa, nosotros proponemos una soluci√≥n **H√≠brida**. Este enfoque busca mitigar el impacto negativo de los altos tiempos de respuesta (24 horas en promedio) en la m√©trica de **Satisfacci√≥n al Cliente** de la compa√±ia **EcoMarket**, en conjunto con un manejo costo-eficiencia, que es tambi√©n importante para la compa√±ia.

---

## 1. Arquitectura General

Nuestro Modelo H√≠brido est√° compuesto por:

1. **Modelo Fine Tuned LLM**, para atender el **80%** de las consultas repetitivas. Ejemplos posibles de uso: GPT-4omini, Gemini 1.5 Flash, Mistral 7B Instruct 
2. **Modelo LLM** de prop√≥sito general, para atender las consultas o preguntas complejas (**20%**). Ejemplos posibles de uso: GPT-4, Claude 3.5 Sonnet.

### ¬øPor qu√©?

Esta arquitectura permite que el modelo Fine-Tuned se enfoque en **eficiencia** y resuelva en menor tiempo las consultas repetitivas que se reciben; mientras que, un modelo LLM (Open source o pagado) contribuye a brindar una  **capacidad de comprensi√≥n** en consultas complejas de los clientes o derivando a un Agente de Call Center, si asi se requiere.  
Esto resolver√° el problema m√°s importante de EcoMarket: **Los tiempos de respuesta que hoy son de 24 horas** y reducirlos a   a **Minutos** con el uso de los agentes de respuesta usando LLM (Large Language Models), que han sido entrenados para esto.  
En cuanto a costos, usar un esquema H√≠brido permite:  
- Operar con un **presupuesto moderado** para resolver la parte repetitiva.  
- **Estimar un costo l√≠mite m√°ximo** al usar un LLM en los casos complejos.  

La elecci√≥n del modelo se basa en un an√°lisis de **costo-beneficio** centrado en la tarea espec√≠fica que debe resolver cada uno de los componentes de la soluci√≥n H√≠brida que proponemos.

---

### 1.1. Para el 80% de Consultas (Repetitivas: Pedidos, Devoluciones, Cat√°logo)

**Modelo Elegido (Ejemplo):** LLM Ligero y Open Source (e.g., *Mistral 7B*) + Afinamiento (Fine-Tuning)

| Criterio               | Justificaci√≥n |
|-------------------------|---------------|
| **Necesidad de Precisi√≥n** | Alta. Una respuesta incorrecta sobre el estado de un pedido (ej: "entregado" cuando est√° "en camino") es cr√≠tica para la satisfacci√≥n al Cliente. |
| **Ventaja del Afinamiento** | Al aplicar Fine-Tuning sobre un modelo ligero base (como Mistral 7B), el modelo aprende el vocabulario, la estructura de las preguntas frecuentes y el tono de EcoMarket. Esto permite rapidez y precisi√≥n en su dominio. |
| **Costo Operacional** | Bajo. Los modelos ligeros son m√°s baratos de alojar en infraestructura propia o en la nube. Solo se activan cuando se requieren, manejando eficientemente el alto tama√±o de preguntas que recibir√°. |

---

### 1.2. Para el 20% de Consultas (Complejas: Quejas, Problemas, Sugerencias)

**Modelo Elegido (Ejemplo):** LLM de Prop√≥sito General de Alto Rendimiento (e.g., *GPT-4o, Gemini 1.5 Pro*)

| Criterio               | Justificaci√≥n |
|-------------------------|---------------|
| **Necesidad de Fluidez/Razonamiento** | Alta. Estas consultas exigen comprender el contexto emocional (empat√≠a), sintetizar informaci√≥n de m√∫ltiples fuentes y seguir instrucciones complejas. |
| **Ventaja de Rendimiento** | Modelos como GPT-4o y Gemini 1.5 Pro poseen razonamiento en cadena (*chain-of-thought*) y uso de herramientas (*Function Calling*). Esto es esencial para clasificar correctamente la queja y determinar a qu√© agente o departamento derivarla, proporcionando al humano un resumen pre-analizado. |
| **Costo Operacional** | Moderado/Alto. El costo por token es mayor, pero al representar solo el 20% del volumen de tr√°fico, la inversi√≥n se justifica porque impacta directamente en la **Satisfacci√≥n al Cliente**. |

---

## 2. Arquitectura Propuesta

Nuestra arquitectura es un **sistema de Orquestaci√≥n** con **decisi√≥n basada en el tr√°fico**, combinando LLM con "Fine-Tuned" y LLM de Prop√≥sito General.

```mermaid
graph TD
    subgraph "Entrada de Consulta"
        A["Cliente: Chat, Email, RRSS"] --> B["Orquestador / Router"];
    end

    subgraph "Clasificaci√≥n - Router Ligero"
        B -- "80% Consultas Repetitivas" --> C["Pedidos, Devoluciones, Cat√°logo"];
        B -- "20% Consultas Complejas" --> G["Quejas, Problemas, Sugerencias"];
    end

    subgraph "Ruta 80% - Consultas Repetitivas"
        C --> D["LLM Fine-Tuned - Ej: Mistral 7B, LLaMA 2-7B"];
        D --> E["RAG conectado a BD de EcoMarket"];
        E --> F["Genera Respuesta Personalizada"];
        F --> Z["Respuesta Autom√°tica Enviada al Cliente"];
    end

    subgraph "Ruta 20% - Consultas Complejas"
        G --> H["LLM Potente - Ej: GPT-4o, Gemini 1.5 Pro, Claude 3 Opus"];
        H --> I["Function Calling / Integraci√≥n CRM & Tickets"];
        I --> J["Genera Resumen o Acci√≥n"];
        J --> K["Agente Humano Ajusta y Env√≠a"];
    end

    %% Estilos
    style A fill:#D4E6F1,stroke:#333,stroke-width:2px;
    style B fill:#AED6F1,stroke:#333,stroke-width:2px;

    style C fill:#C0F6C0,stroke:#333,stroke-width:2px;
    style D fill:#C0F6C0,stroke:#333,stroke-width:2px;
    style E fill:#C0F6C0,stroke:#333,stroke-width:2px;
    style F fill:#C0F6C0,stroke:#333,stroke-width:2px;
    style Z fill:#D4E6F1,stroke:#333,stroke-width:2px;

    style G fill:#F6C0C0,stroke:#333,stroke-width:2px;
    style H fill:#F6C0C0,stroke:#333,stroke-width:2px;
    style I fill:#F6C0C0,stroke:#333,stroke-width:2px;
    style J fill:#F6C0C0,stroke:#333,stroke-width:2px;
    style K fill:#F6C0C0,stroke:#333,stroke-width:2px;
```
### 2.1. Arquitectura L√≥gica

1. **Orquestador/Enrutador:**  
   - Recibe cada consulta del cliente.  
   - Usa un modelo ligero (ej: *GPT-4o Mini*) afinado para clasificaci√≥n.  
   - Decide: ¬øEs repetitiva (80%) o compleja (20%)?  

2. **Ruta del 80% (Eficiencia):**  
   - La consulta pasa al **Modelo Fine-Tuned LLM**.
   - Este modelo integra una capa de **Generaci√≥n Aumentada por Recuperaci√≥n (RAG)** para interactuar con la Base de Datos de EcoMarket (solo lectura de datos est√°ticos y f√°cticos, ej. estados de env√≠o, descripci√≥n de productos, devoluciones).

3. **Ruta del 20% (Capacidad):**
   - Si es compleja, la consulta pasa al **Modelo LLM**.
   - Este modelo usa la funcionalidad de Llamada a Funciones **(Function Calling)** para iniciar procesos especializados (ej: registrar una queja en el CRM o generar un ticket de soporte).
   - Si el modelo determina que la pregunta supera su capacidad de resoluci√≥n (ej. requiere una negociaci√≥n con el cliente), lo env√≠a a un Agente de Call Center, acompa√±ado de un **resumen** y un **sentiment score**.
   
---

### 2.2. Integraci√≥n con la Base de Datos (BD) de EcoMarket

| Mecanismo de Integraci√≥n | Prop√≥sito | Aplicaci√≥n en EcoMarket |
|--------------------------|-----------|--------------------------|
| **RAG (Retrieve Augmented Generation)** | Consultar datos en tiempo real (solo lectura). | Estado del pedido, informaci√≥n de env√≠o, inventario y cat√°logo. |
| **Function Calling / Herramientas** | Ejecutar acciones o registrar datos (lectura y escritura). | Registrar una devoluci√≥n, actualizar el status de una queja, o ejecutar un script de diagn√≥stico para un problema t√©cnico, ej.: Pedido no registrado, falla en acceso al portal de Ecomarket, etc. |

---

## 3. Justificaci√≥n

| Criterio               | Justificaci√≥n |
|-------------------------|---------------|
| **Costo** | Optimizaci√≥n del TCO. El 80% del tr√°fico va a un LLM Fine-Tuned econ√≥mico (ej. Mistral 7B). Solo se paga un modelo premium para el 20% de casos cr√≠ticos. |
| **Escalabilidad** | La parte repetitiva que corresponde al 80%, se  puede manejar con un esquema de cluster uando equipos con GPUs econ√≥micas en DataCenter o por demanda en Nube P√∫blica. La parte compleja, que corresponde al 20% , se trabaja en la nube de proveedores de LLM de alto nivel: OpenAI/Google. Donde se puede establecer un uso m√°ximo pagado para brindar las respuestas a las solicitudes de este tipo. |
| **Facilidad de Integraci√≥n** | Uso de est√°ndares como RAG y Function Calling, lo que simplifica el desarrollo y reduce la curva de aprendizaje del equipo de ingenier√≠a del cliente. |
| **Calidad de Respuesta** | Precisi√≥n garantizada en el 80% repetitivo (Fine-Tuning + RAG) y razonamiento superior en el 20% complejo con el uso  de modelos avanzados. |

---

# Fase II - Evaluaci√≥n de Fortalezas, Limitaciones y Riesgos √âticos

### 4. Fortalezas
- **Reducci√≥n en los Tiempos de Respuesta de Servicio al Cliente:**  
  Es definitivamente el principal beneficio. El 80% de las consultas se resuelven en minutos, no en horas, impactando de manera positiva la m√©trica de **Satisfacci√≥n del Cliente**, que es al final lo solicitado por la compa√±ia.
  
- **Disponibilidad 24/7:**  
  Por ser un modelo "Fine Tuned LLM", estar√° disponible de manera continua, 7x24, para manejar el alto volumen de consultas repetitivas. Esto de nuevo, redunda de manera positiva en la **Satisfacci√≥n al Cliente**.

- **Coherencia y Consistencia:**  
  Se asegura una √∫nica fuente de informaci√≥n para el alto volumen repetitivo de preguntas, eliminando las variaciones y errores que surgen de las respuestas humanas. En otras palabras habr√° una tendencia a la reducci√≥n en respuestas err√≥neas, inconsistentes o la demora en las respuestas a todas estas solicitudes que se reciban.

- **Especializaci√≥n de la Labor del Agente Humano:**  
  Los agentes se liberan del trabajo repetitivo, pudiendo enfocarse solo en el 20% que corresponde a los casos complejos, donde su empat√≠a y pensamiento cr√≠tico son realmente valiosos.

---

### 5. Limitaciones
- **Limitaci√≥n en la Empat√≠a:**  
  Si bien se ofrece un "fine tuned LLM" al igual que un Modelo LLM para responder a lo repetitivo y lo complejo. En los casos donde se requiere negociaci√≥n o manejo de crisis, estos modelos no pueden replicar la inteligencia emocional de un agente humano. Es por eso, que el Agente de Call Center debe atender al cliente en estas situaciones y no puede estar fuera del proceso.

- **Dependencia en la Calidad de los Datos:**  
  Si queremos contar con una precisi√≥n mayor o igual al 80%, dependeremos completamente de la exactitud y limpieza de la **Base de Datos de EcoMarket**.  
  Si hay errores, informaci√≥n incompleta, muy pocos datos o inexistentes, el **LLM Fine-Tuned** generar√° respuestas erroneas o equivocadas o empezar√° a alucinar. Esto afectara la **Satisfacci√≥n al Cliente** y pondr√° en riesgo la reputaci√≥n de la compa√±ia. Es lo que siempre se maneja como lema en la Inteligencia Artificial: **Basura Entra (Garbage In)** -->  **Basura Sale (Garbage Out)**

- **Costos de Entrenamiento (Fine-Tuning):**  
 La inversi√≥n inicial en tiempo y recursos para afinar el modelo y alcanzar una precisi√≥n igual o superior al 80% puede ser considerable. Sin embargo, estimamos que este esfuerzo resultar√° m√°s econ√≥mico que depender de un LLM con costos recurrentes de tokens y llamadas a API. Por ello, ser√° fundamental una planificaci√≥n adecuada que mantenga los costos bajo control y garantice la viabilidad del proyecto.

---

### 6. Riesgos √âticos y de Gobernanza de Datos
- **Alucinaciones:**  
  Siempre existe el riesgo de que LM  invente informaci√≥n (una *"alucinaci√≥n"*) al generar datos de pedidos, productos, un resumen o un diagn√≥stico complejo.  
  *Mitigaci√≥n:* Implementar filtros de verificaci√≥n de hechos en la fase de **Function Calling** antes de generar la respuesta al cliente y mecanismo de validaci√≥n de respuestas a las preguntas repetitivas.

- **Sesgo:**  
  Si los datos utilizados para el Fine-Tuning contienen sesgos hist√≥ricos (ej. si las quejas de un grupo demogr√°fico espec√≠fico fueron mal manejadas hist√≥ricamente), el modelo podr√≠a perpetuar y automatizar ese trato preferencial o injusto.  
  *Mitigaci√≥n:* Auditor√≠a de sesgos en el dataset de entrenamiento y en las respuestas generadas.

- **Privacidad de Datos:**  
  Al integrar la BD de clientes (direcciones, historial de compras, entre otros) en el contexto de los prompts (ya sea **RAG** o **Function Calling**), se debe asegurar que:  
  1. Los datos est√°n anonimizados o se accede solo a la informaci√≥n m√≠nima necesaria.  
  2. Se implementa un estricto control de acceso y almacenamiento temporal del contexto (*borrado inmediato despu√©s de la respuesta*).
  3. Autenticaci√≥n de usuarios para identificar qui√©n accede y tener una auditor√≠a de todo el flujo de interacci√≥n.
  4. Usar un "Servicio Intermedio" para evitar que alguno de los modelos LLM usados interactu√© directamente con la o las bases de datos de **EcoMarket**

- **Impacto Laboral:**
  Los cambios Tecnologicos o de algun otro tipo en las compa√±ias siempre generan incertidumbre en la fuerza laboral activa. Tenemos claro que habr√° reducci√≥n del personal actual de Agentes usado para el servicio al cliente. Debemos manter como objetivo principal: que se trata de **mejorar, empoderar y no reemplazar**. La propuesta debe ser vista por EcoMarket como una herramienta que eleva el trabajo de los agentes de soporte, permiti√©ndoles enfocarse en la calidad y la retenci√≥n del cliente, en lugar de en la cantidad de tickets repetitivos que son lo que a hoy esta desbordado, haciendolo ineficiente y con alta tasa de insatisfacci√≥n; lo que es cr√≠tico para una compa√±ia emergente como EcoMarket.

  # Fase III - Aplicaci√≥n de Ingenier√≠a de Prompts

  A continuaci√≥n presentamos los **PROMPTS** que hemos dise√±ado para los dos (2) requerimientos que se solicitan.

  ### 1. Estado de Solicitud de Pedido

  prompt_pedido =
  f"""
  Eres un agente de servicio al cliente amable, profesional y conciso.
  Tu √∫nica tarea es proporcionar el estado del pedido {num_pedido} con un **lenguaje natural y conversacional**, bas√°ndote estrictamente en la siguiente informaci√≥n:

  - **N√∫mero de Pedido:** {num_pedido}
  - **Estado Actual:** {estado}
  - **Fecha de Entrega Estimada:** {estimacion_formateada}
  - **Retrasado:** {retrasado}
   {instruccion_tracking_data}

   **INSTRUCCIONES DE FORMATO DE RESPUESTA:**
   1.  Comienza con una frase que indique el estado y la estimaci√≥n de entrega (si aplica), usando el formato: "Su orden {num_pedido} se encuentra {frase_estado}. La fecha de entrega estimada es {estimacion_formateada}."
   2.  Si la estimaci√≥n es 'No aplica' (como en el caso de 'Cancelado' o 'Entregado'), omite la parte de la fecha de entrega, solo indica el estado.
{instruccion_tracking} 4. Si **Retrasado** es True, a√±ade el siguiente mensaje al final: "Nos excusamos por la demora en la entrega y estamos trabajando para que pueda contar con su orden lo mas pronto posible."
   5.  Si el **Estado Actual** es 'Cancelado', a√±ade el siguiente mensaje al final: "Lamentamos los inconvenientes y le invitamos a comunicarse con nuestro centro de servicios al Nro. 01-800-XXX-XXXX para tener m√°s detalles."
   6.  **IMPORTANTE:** Tu respuesta NO debe contener encabezados, listas numeradas, ni repetir la informaci√≥n de entrada, solo debe generar el texto conversacional.

  Respuesta:
  """

  ### 2. Devoluci√≥n de Producto

     prompt = 
     f"""
     Act√∫a como un agente de servicio al cliente amable y profesional.
      Usa la siguiente base de datos de productos:

     {base_datos_devoluciones}

     Instrucciones para el Asistente:
     1. Responde inmediatamente al cliente siguiendo las instrucciones de formato.
     2. Identifica el producto por su ID (ej. Producto 2002) y su nombre.
     3. Revisa si el producto es retornable.
     4. Si es retornable, indica **Retornable** y explica el proceso.
     5. Si NO es retornable, indica **No retornable**, explica la raz√≥n y ofrece alternativas/descuentos.
     6. Da la respuesta en el siguiente formato:
      - **Estado del producto**: (Retornable / No retornable)
      - **Explicaci√≥n**
      - **Siguientes pasos / Alternativas**
    7. Mant√©n la respuesta clara y concisa, m√°ximo 5 p√°rrafos.
    8. Usa un tono c√°lido, humano y profesional.

    ---
    Cliente: Hola, estoy devolviendo {producto_buscado} por {motivo}, ¬øqu√© debo hacer?

    {MARCADOR_ASISTENTE}"""

### 3. Prueba de los PROMPTS

En este Repositorio de GitHub hay un Google Colab Notebook que se llama **IAG_Taller1_Fase_3.ipynb**, donde hicimos las pruebas con los dos (2) Prompts dise√±ados. 

El LLM (Large Language Model) que usamos fue: mistralai/Mistral-7B-Instruct-v0.2. 

**¬øPor qu√© este LLM ?**
De los modelos que consultamos y revisamos, seleccionamos este en especial por las siguientes razones:
- Fue ajustado (fine-tuned) con ejemplos de instrucciones y respuestas humanas, que es lo que tiene mayor relevancia al usarlo en la creaci√≥n de PROMPTS.
- Est√° optimizado para seguir PROMPTS *tipo instrucciones*, como los que estamos usando en el dise√±o:
    - ‚ÄúAct√∫a como un agente de servicio al cliente‚Ä¶‚Äù
    - ‚ÄúResponde en formato claro y conciso‚Ä¶‚Äù
    - ‚ÄúDevu√©lveme solo este campo‚Ä¶‚Äù
- Y por √∫ltimo, pudimos notar que produce respuestas m√°s estructuradas, coherentes y √∫tiles en comparaci√≥n con un modelo de transformers con BERT e inclusive algunos modelos de Generaci√≥n de Texto.

### 4. Ejecuci√≥n del Google Colab Notebook.
Para ejcutarlo solo se requiere dar **"Clic"** con el rat√≥n en el icono **"Open Google Colab"** que aparece en el archivo **IAG_Taller1_Fase_3.ipynb**
